{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374e84f8",
   "metadata": {},
   "source": [
    "# Project 2: Reproducibility in Natural Language Processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6523ab",
   "metadata": {},
   "source": [
    "## Part 4: Choose your own advecnture! (7 Points; Optional for Extra Credit)\n",
    "\n",
    "This section is open ended and your chance to explare any advanced analysis. Please perform any additional analysis you find interesting! Suggested analyses (only do one max):\n",
    "\n",
    "- Topic evolution over time - see https://maartengr.github.io/BERTopic/getting_started/topicsovertime/topicsovertime.html#visualization \n",
    "- Word frequency over time - does the frequency of certain words change over time\n",
    "- Semantic similarity - investigate similarity within and between presidents or time periods. For example, similarity between one presidents speeches, e.g. are all of Biden's speeches similar to each other? How similar are they to Trump's speeches? Are speeches from the 2000s more similar to each other than speeches in the 1800s? Which two presidents have the most similar speeches? See https://spacy.io/usage/linguistic-features#vectors-similarity \n",
    "-  Named Entity Recognition - which entity types are most common in speeches? What are the most common words for each entity type - see https://spacy.io/usage/linguistic-features#named-entities \n",
    "- Classification - can you build a classifier to detect democratic versus republican state of the union speeches from 1980-2024 - see https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0978a6a-3b1b-46ab-87f8-d8eea962995e",
   "metadata": {},
   "source": [
    "### Word Frequency Over Time Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ed4fd9-db9d-4e24-ae96-276dba7b8f11",
   "metadata": {},
   "source": [
    "In this analysis, we examine how the frequency of commonly used words changes over time in **State of the Union (SOTU) speeches**. Using SpaCy for linguistic preprocessing, each speech is tokenized, lemmatized, and filtered to remove stopwords, punctuation, and non-alphabetic tokens. We then compute yearly word counts and track the frequency of the top 10 most frequent content words across more than two centuries of presidential speeches.\n",
    "\n",
    "The resulting time-series visualizations—along with 4-year rolling averages—highlight long-run shifts in presidential rhetoric, revealing how themes related to national identity, economic conditions, and global affairs rise and fall alongside major historical events and political priorities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f908d956-5875-44b5-8557-edbb26cfd4c2",
   "metadata": {},
   "source": [
    "### Methods: Text Preprocessing and Frequency Analysis\n",
    "\n",
    "All text analysis was conducted using SpaCy’s `en_core_web_sm` model. Each speech was processed using the following steps:\n",
    "\n",
    "1. **Normalization:** Convert text to lowercase.\n",
    "2. **Tokenization:** Split text into lexical tokens using SpaCy's tokenizer.\n",
    "3. **Lemmatization:** Replace each token with its lemma (base form) to unify variants such as *working* → *work*.\n",
    "4. **Filtering:**  \n",
    "   - Remove punctuation and non-alphabetic tokens  \n",
    "   - Remove SpaCy stopwords  \n",
    "5. **Aggregation:**  \n",
    "   - For each year, merge all tokens from speeches delivered that year  \n",
    "   - Compute word counts using `collections.Counter`  \n",
    "6. **Visualization:**  \n",
    "   - Construct a word–year frequency dataframe  \n",
    "   - Plot yearly frequencies  \n",
    "   - Add a 4-year centered rolling average to smooth variability\n",
    "\n",
    "These steps ensure consistent and reproducible text preprocessing across all historical documents, allowing for meaningful comparisons of word usage patterns over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861811fd-093b-4a64-b663-5b09bd683c9b",
   "metadata": {},
   "source": [
    "### 1. Setup: Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf212f72-a74f-4a01-ab02-43bbbebfa948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "plt.style.use('seaborn-v0_8-dark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35b19bbc-e384-4ba1-aced-e2cf808986c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c3217f9-a41b-40be-809e-bafc3445d95c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sou = pd.read_csv(\"data/SOTU.csv\")\n",
    "sou['Year'] = sou['Year'].astype(int)\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693aecdb-8777-4e28-94bf-273228ae0de4",
   "metadata": {},
   "source": [
    "### 2. Preprocess text and count words per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdfaeae-702a-451b-b7a2-60674051aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase, remove stopwords/punctuation\n",
    "def tokenize_text(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_.lower() for token in doc \n",
    "              if not token.is_stop and not token.is_punct and token.is_alpha]\n",
    "    return tokens\n",
    "\n",
    "# Apply tokenization to each speech\n",
    "sou['Tokens'] = sou['Text'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0089c1d6-4a5e-4c24-b906-9b251ebdf681",
   "metadata": {},
   "source": [
    "### 3. Aggregate word counts by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69232f30-2ffa-4848-bd49-97c5c05bebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Year\n",
    "years = sorted(sou['Year'].dropna().unique())\n",
    "word_counts_by_year = {}\n",
    "\n",
    "for year in years:\n",
    "    texts = sou[sou['Year'] == year]['Tokens']\n",
    "    all_tokens = [token for tokens in texts for token in tokens]\n",
    "    word_counts_by_year[year] = Counter(all_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0465e4d9-1fdc-44a0-8d0d-c69564572a23",
   "metadata": {},
   "source": [
    "### 4. Analyze frequency of selected words over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04106428-509e-4af5-919f-2b71c3f2dea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_track = ['year',\n",
    " 'america',\n",
    " 'people',\n",
    " 'american',\n",
    " 'work',\n",
    " 'new',\n",
    " 'job',\n",
    " 'country',\n",
    " 'americans',\n",
    " 'world'] # top ten most common words through whole corpus\n",
    "\n",
    "# Build a dataframe\n",
    "freq_df = pd.DataFrame(index=years, columns=words_to_track)\n",
    "\n",
    "for year in years:\n",
    "    for word in words_to_track:\n",
    "        freq_df.loc[year, word] = word_counts_by_year[year].get(word, 0)\n",
    "\n",
    "freq_df = freq_df.astype(int)\n",
    "freq_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6fd898-8a25-4c5c-b6f4-09022aec2638",
   "metadata": {},
   "source": [
    "### 5. Plot word frequencies over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5a782b-4e94-4140-905a-3e338101e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots (one row per word)\n",
    "fig, axes = plt.subplots(len(words_to_track), 1, figsize=(12, 3*len(words_to_track)), sharex=True)\n",
    "\n",
    "# Rolling window size (in years)\n",
    "window_size = 4\n",
    "\n",
    "for i, word in enumerate(words_to_track):\n",
    "    # Original counts\n",
    "    axes[i].plot(freq_df.index, freq_df[word], marker='o', alpha=0.5, label='Original', color='b')\n",
    "    \n",
    "    # Rolling average\n",
    "    rolling_series = freq_df[word].rolling(window=window_size, min_periods=1).mean()\n",
    "    axes[i].plot(freq_df.index, rolling_series, marker='o', label=f'{window_size}-Year Rolling Avg', color='r')\n",
    "    \n",
    "    axes[i].set_ylabel(\"Count\")\n",
    "    axes[i].set_title(f\"'{word}' Frequency Over Time\")\n",
    "    axes[i].grid(True)\n",
    "    axes[i].legend()\n",
    "\n",
    "# X-axis label only on the bottom subplot\n",
    "axes[-1].set_xlabel(\"Year\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"outputs/top_10_words_freq_over_time.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f53c15-646b-4da3-acbe-5bcf33e24c3d",
   "metadata": {},
   "source": [
    "### Summary of Word Frequency Trends Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b0cc82-a92b-465c-83c5-e10f183a1543",
   "metadata": {},
   "source": [
    "To study how the thematic focus of U.S. Presidents has shifted across more than two centuries of State of the Union (SOTU) speeches, we analyzed the frequency of several commonly used political terms—such as year, america, people, american, work, new, job, country, americans, and world. Using SpaCy for lemmatization and stopword removal, word counts were aggregated by year and visualized with both raw frequencies and a 4-year rolling average to smooth short-term noise.\n",
    "\n",
    "#### Key Observations\n",
    "\n",
    "1. Long-run upward trend in many terms\n",
    "Words like america, american, people, and country show a significant increase in usage beginning in the early 20th century. This reflects both longer speeches and a shift toward more populist, national identity–centered rhetoric.\n",
    "\n",
    "2. Mid-20th-century spikes\n",
    "Several terms show clear spikes during major historical periods:\n",
    "    - war-adjacent words rise sharply during WWI, WWII, and the early Cold War.\n",
    "    - world peaks especially around WWII and the globalist era following it.\n",
    "\n",
    "3. Shifts in economic language\n",
    "Words such as work, job, and economy grow noticeably starting in the 1930s, consistent with the Great Depression, New Deal, and the increasing focus on labor, employment, and fiscal policy in modern presidencies.\n",
    "\n",
    "4. Modern rhetorical expansion\n",
    "From the 1980s onward, terms relating to america, americans, and people stabilize at high frequencies, matching modern presidential communication styles that emphasize unity, national identity, and broad public appeal.\n",
    "\n",
    "5. Rolling average helps uncover structure\n",
    "The 4-year smoothing reveals persistent trends that are otherwise obscured by year-to-year variability, showing clearer long-run thematic cycles tied to political eras, wars, and economic conditions.\n",
    "\n",
    "#### Interpretation\n",
    "\n",
    "Overall, the evolution of word frequencies reveals how presidential priorities and communication strategies have changed over time—from early, formal constitutional reporting to modern speeches focused on national identity, global affairs, and the economy. The results show that simple frequency analysis, when combined with linguistic preprocessing and long-run smoothing, can meaningfully capture shifts in political discourse across centuries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3837e319-555f-4be6-ab02-39c2aeeb2321",
   "metadata": {},
   "source": [
    "#### Detailed Summary on Each Word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427c4c3e-c914-4c42-80d0-26e54d8ba46a",
   "metadata": {},
   "source": [
    "1. “year”\n",
    "\n",
    "\n",
    "Used mainly in phrases like “this year,” “last year,” or “in the coming year,” its frequency grows over time with speech length. Peaks often align with major transitions, crises, or agenda-setting years—periods when presidents emphasize timelines and legislative plans.\n",
    "\n",
    "2. “america”\n",
    "\n",
    "Steadily rises across the 20th and 21st centuries, reflecting an increasing emphasis on national framing. The spike during modern presidencies aligns with a more narrative-driven, patriotic speech style.\n",
    "\n",
    "3. “people”\n",
    "\n",
    "\n",
    "Grows sharply in the 20th century as presidents adopt more populist and direct communication styles. Used to emphasize democratic values, collective responsibility, and public sentiment.\n",
    "\n",
    "4. “american”\n",
    "\n",
    "Shows major rises during wartime and the Cold War, when appeals to national unity and identity became central. High modern usage reflects a continued emphasis on shared national identity.\n",
    "\n",
    "5. “work”\n",
    "\n",
    "Increases around the Great Depression and post-WWII era, mirroring shifts in economic policy focus, labor issues, and job creation as core political priorities.\n",
    "\n",
    "6. “new”\n",
    "\n",
    "Major spikes around the “New Deal” era of FDR (1930s) and the “New Frontier” era of JFK (1960s). Usage corresponds to reform-heavy periods when administrations introduce large policy agendas.\n",
    "\n",
    "7. “job”\n",
    "\n",
    "Barely present before the 20th century. Becomes prominent in the post-industrial economy, especially from the 1970s onward, reflecting the increasing political salience of employment and labor markets.\n",
    "\n",
    "8. “country”\n",
    "\n",
    "Used consistently but rises in modern speeches. Peaks often coincide with wars or national crises, as presidents emphasize unity, security, and collective purpose.\n",
    "\n",
    "9. “americans”\n",
    "\n",
    "Shows a clear modern upward trend. More conversational than “the American people,\" it signals increasingly direct public engagement and rhetorical personalization.\n",
    "\n",
    "10. “world”\n",
    "\n",
    "Spikes during major global conflicts—WWI, WWII, and early Cold War—reflecting America’s growing international role. Elevated usage continues in the post-war era due to foreign policy centrality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sotu)",
   "language": "python",
   "name": "sotu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
